import OpenAI from 'openai';
import { readFile } from 'fs/promises';
import { statSync, existsSync, unlinkSync } from 'fs';
import { basename, join, dirname } from 'path';
import ffmpeg from 'fluent-ffmpeg';
import config from '../config/config.js';

/**
 * Formatea tiempo en segundos a formato legible (segundos, minutos o horas)
 * @param {number} seconds - Tiempo en segundos
 * @returns {string} - Tiempo formateado (ej: "45.23s", "1.25min", "1.50h")
 */
function formatTime(seconds) {
  if (seconds < 60) {
    return `${seconds.toFixed(2)}s`;
  } else if (seconds < 3600) {
    const minutes = seconds / 60;
    return `${minutes.toFixed(2)}min`;
  } else {
    const hours = seconds / 3600;
    return `${hours.toFixed(2)}h`;
  }
}

const openai = new OpenAI({
  apiKey: config.openai.apiKey,
});

/**
 * Funci√≥n para mostrar log en formato unificado (importada desde videoController)
 */
let showLogCallback = null;

/**
 * Establece el callback para mostrar logs
 * @param {Function} callback - Funci√≥n callback para mostrar logs
 */
export function setLogCallback(callback) {
  showLogCallback = callback;
}

/**
 * Comprime un archivo de audio para reducir su tama√±o
 * @param {string} inputPath - Ruta del archivo original
 * @param {string} outputPath - Ruta donde guardar el archivo comprimido
 * @returns {Promise<string>} - Ruta del archivo comprimido
 */
async function compressAudio(inputPath, outputPath, videoNumber = 1, totalVideos = 1, videoId = '') {
  return new Promise((resolve, reject) => {
    // Calcular bitrate objetivo para que el archivo sea aproximadamente 20MB
    const stats = statSync(inputPath);
    const originalSizeMB = stats.size / (1024 * 1024);
    const targetSizeMB = 20; // Objetivo: 20MB para dejar margen
    const targetBitrate = Math.max(32, Math.min(128, Math.floor((targetSizeMB / originalSizeMB) * 128)));
    
    ffmpeg(inputPath)
      .audioCodec('libmp3lame')
      .audioBitrate(targetBitrate)
      .audioChannels(1) // Mono para reducir tama√±o
      .audioFrequency(16000) // 16kHz es suficiente para transcripci√≥n
      .output(outputPath)
      .on('progress', (progress) => {
        if (progress.percent !== undefined && showLogCallback) {
          showLogCallback('üóúÔ∏è', videoNumber, totalVideos, videoId, 'Comprimiendo audio', progress.percent, null);
        }
      })
      .on('end', () => {
        if (showLogCallback) {
          showLogCallback('üóúÔ∏è', videoNumber, totalVideos, videoId, 'Comprimiendo audio', 100, null);
        }
        resolve(outputPath);
      })
      .on('error', (err) => {
        reject(new Error(`Error al comprimir audio: ${err.message}`));
      })
      .run();
  });
}

/**
 * Transcribe un archivo de audio usando Whisper
 * @param {string} audioPath - Ruta del archivo de audio
 * @param {number} videoNumber - N√∫mero del video (para logs)
 * @param {number} totalVideos - Total de videos (para logs)
 * @param {string} videoId - ID del video (para logs)
 * @returns {Promise<{transcription: string, srt: string, segments: Array}>}
 */
export async function transcribeAudio(audioPath, videoNumber = 1, totalVideos = 1, videoId = '') {
  // Verificar API key
  if (!config.openai.apiKey || config.openai.apiKey.trim() === '') {
    throw new Error('OPENAI_API_KEY no est√° configurada o est√° vac√≠a. Verifica tu archivo .env');
  }

  let audioToTranscribe = audioPath;
  let compressedAudioPath = null;

  try {
    // Obtener tama√±o del archivo para estimar tiempo
    const stats = statSync(audioPath);
    const fileSizeMB = stats.size / (1024 * 1024);
    
    // Si el archivo es mayor a 25MB, comprimirlo
    if (fileSizeMB > 25) {
      // Crear ruta para el archivo comprimido
      const dir = dirname(audioPath);
      const baseName = basename(audioPath, '.mp3');
      compressedAudioPath = join(dir, `${baseName}_min.mp3`);
      
      // Verificar si el audio comprimido ya existe
      if (existsSync(compressedAudioPath)) {
        audioToTranscribe = compressedAudioPath;
        
        // Verificar el tama√±o del archivo comprimido
        const compressedStats = statSync(compressedAudioPath);
        const compressedSizeMB = compressedStats.size / (1024 * 1024);
        
        if (compressedSizeMB > 25) {
          // Si a√∫n es muy grande, intentar con la versi√≥n m√°s comprimida
          const moreCompressedPath = join(dir, `${baseName}_min2.mp3`);
          if (existsSync(moreCompressedPath)) {
            audioToTranscribe = moreCompressedPath;
            compressedAudioPath = moreCompressedPath;
          } else {
            if (showLogCallback) {
              showLogCallback('üóúÔ∏è', videoNumber, totalVideos, videoId, 'Comprimiendo audio', null, null);
            }
            audioToTranscribe = await compressAudio(audioPath, moreCompressedPath, videoNumber, totalVideos, videoId);
            compressedAudioPath = moreCompressedPath;
          }
        }
      } else {
        if (showLogCallback) {
          showLogCallback('üóúÔ∏è', videoNumber, totalVideos, videoId, 'Comprimiendo audio', null, null);
        }
        // Comprimir el audio
        audioToTranscribe = await compressAudio(audioPath, compressedAudioPath, videoNumber, totalVideos, videoId);
        
        // Verificar el tama√±o del archivo comprimido
        const compressedStats = statSync(compressedAudioPath);
        const compressedSizeMB = compressedStats.size / (1024 * 1024);
        
        if (compressedSizeMB > 25) {
          // Si a√∫n es muy grande, comprimir m√°s agresivamente
          const moreCompressedPath = join(dir, `${baseName}_min2.mp3`);
          audioToTranscribe = await compressAudio(audioPath, moreCompressedPath, videoNumber, totalVideos, videoId);
          compressedAudioPath = moreCompressedPath;
        }
      }
    }
    
    // Obtener tama√±o del archivo a transcribir (puede ser el comprimido)
    const finalStats = statSync(audioToTranscribe);
    const finalSizeMB = finalStats.size / (1024 * 1024);
    
    let transcription;
    try {
      // Leer el archivo completo como buffer (necesario para File API)
      const audioBuffer = await readFile(audioToTranscribe);
      const fileName = basename(audioToTranscribe);
      
      // Crear un objeto File para la API de OpenAI
      // En Node.js 18+, File est√° disponible globalmente
      let file;
      if (typeof File !== 'undefined') {
        file = new File([audioBuffer], fileName, { 
          type: 'audio/mpeg',
          lastModified: stats.mtimeMs
        });
      } else {
        // Fallback: usar el buffer directamente (puede funcionar en algunas versiones)
        file = audioBuffer;
        file.name = fileName;
        file.type = 'audio/mpeg';
      }

      // Transcribir con Whisper con timeout y reintentos
      const startTime = Date.now();
      let lastUpdate = Date.now();
      
      // Estimar tiempo de transcripci√≥n basado en el tama√±o del archivo
      // Whisper procesa aproximadamente 1MB por segundo (estimaci√≥n conservadora)
      let estimatedDuration = Math.max(30, finalSizeMB * 1.5); // M√≠nimo 30s, o 1.5s por MB
      let lastElapsed = 0;
      
      // Funci√≥n auxiliar para detectar errores de conexi√≥n
      const isConnectionError = (error) => {
        const errorMessage = error.message || '';
        const errorCode = error.code || '';
        return (
          errorMessage.includes('Connection error') ||
          errorMessage.includes('ECONNREFUSED') ||
          errorMessage.includes('ECONNRESET') ||
          errorMessage.includes('ETIMEDOUT') ||
          errorMessage.includes('ENOTFOUND') ||
          errorMessage.includes('network') ||
          errorMessage.includes('fetch failed') ||
          errorCode === 'ECONNREFUSED' ||
          errorCode === 'ECONNRESET' ||
          errorCode === 'ETIMEDOUT' ||
          errorCode === 'ENOTFOUND'
        );
      };
      
      // Sistema de reintentos para errores de conexi√≥n
      const maxRetries = 3;
      let retryCount = 0;
      let progressInterval = null;
      
      while (retryCount <= maxRetries) {
        try {
          // Simular progreso mientras transcribe
          progressInterval = setInterval(() => {
            const elapsed = (Date.now() - startTime) / 1000;
            
            // Ajustar din√°micamente la estimaci√≥n si est√° tomando m√°s tiempo del esperado
            // Si han pasado m√°s de 10 segundos y el progreso estimado ser√≠a > 100%, ajustar la duraci√≥n estimada
            if (elapsed > 10 && (elapsed / estimatedDuration) * 100 > 90) {
              // Ajustar la duraci√≥n estimada para que el progreso sea m√°s realista
              // Usar una funci√≥n logar√≠tmica para que el progreso avance m√°s lentamente cuando se acerca al final
              estimatedDuration = elapsed / 0.95; // Ajustar para que el progreso est√© en ~95% cuando ha pasado este tiempo
            }
            
            // Calcular progreso con funci√≥n logar√≠tmica para que avance m√°s r√°pido al inicio y m√°s lento al final
            // Esto hace que el progreso sea m√°s realista visualmente
            const linearProgress = Math.min(0.99, (elapsed / estimatedDuration));
            // Aplicar curva logar√≠tmica suave para que el progreso no se estanque
            const estimatedProgress = Math.min(99, linearProgress * 100);
            
            if (showLogCallback && Date.now() - lastUpdate > 500) {
              const statusText = retryCount > 0 ? `Transcribiendo (reintento ${retryCount})` : 'Transcribiendo';
              showLogCallback('üé§', videoNumber, totalVideos, videoId, statusText, estimatedProgress, elapsed);
              lastUpdate = Date.now();
              lastElapsed = elapsed;
            }
          }, 500);
          
          transcription = await Promise.race([
            openai.audio.transcriptions.create({
              file: file,
              model: 'whisper-1',
              response_format: 'verbose_json',
              language: 'es', // Espa√±ol
              timestamp_granularities: ['segment'],
            }),
            new Promise((_, reject) => 
              setTimeout(() => reject(new Error('Timeout: La transcripci√≥n tard√≥ m√°s de 5 minutos')), 300000)
            )
          ]);
          
          // √âxito: salir del bucle de reintentos
          break;
        } catch (apiError) {
          // Limpiar intervalo de progreso
          if (progressInterval) {
            clearInterval(progressInterval);
            progressInterval = null;
          }
          
          // Si es un error de conexi√≥n y a√∫n tenemos reintentos disponibles
          if (isConnectionError(apiError) && retryCount < maxRetries) {
            retryCount++;
            const delay = Math.min(5000 * retryCount, 15000); // Backoff exponencial: 5s, 10s, 15s
            
            if (showLogCallback) {
              showLogCallback('üé§', videoNumber, totalVideos, videoId, `Error de conexi√≥n. Reintentando en ${delay/1000}s... (${retryCount}/${maxRetries})`, null, null);
            }
            
            // Esperar antes de reintentar
            await new Promise(resolve => setTimeout(resolve, delay));
            
            // Reiniciar el tiempo de inicio para el nuevo intento
            startTime = Date.now();
            lastUpdate = Date.now();
            continue; // Reintentar
          }
          
          // Si no es un error de conexi√≥n o se agotaron los reintentos, lanzar el error
          // Mejorar mensajes de error
          if (isConnectionError(apiError)) {
            throw new Error('Error de conexi√≥n con la API de OpenAI despu√©s de varios intentos. Verifica tu conexi√≥n a internet y que la API key sea v√°lida.');
          } else if (apiError.message.includes('401') || apiError.message.includes('Unauthorized')) {
            throw new Error('API key de OpenAI inv√°lida. Verifica tu OPENAI_API_KEY en el archivo .env');
          } else if (apiError.message.includes('429') || apiError.message.includes('rate limit')) {
            throw new Error('L√≠mite de tasa excedido. Espera un momento antes de intentar de nuevo.');
          } else if (apiError.message.includes('413') || apiError.message.includes('too large')) {
            throw new Error('El archivo de audio es demasiado grande para la API de Whisper.');
          } else {
            throw new Error(`Error en la API de OpenAI: ${apiError.message}`);
          }
        }
      }
      
      // Limpiar intervalo de progreso si a√∫n est√° activo
      if (progressInterval) {
        clearInterval(progressInterval);
      }
      
      const elapsed = (Date.now() - startTime) / 1000;
      if (showLogCallback) {
        showLogCallback('üé§', videoNumber, totalVideos, videoId, 'Transcribiendo', 100, elapsed);
      }
    } catch (apiError) {
      
      // Limpiar archivo comprimido si existe y hay error
      // if (compressedAudioPath && existsSync(compressedAudioPath)) {
      //   try {
      //     unlinkSync(compressedAudioPath);
      //   } catch (e) {
      //     // Ignorar errores de limpieza
      //   }
      // }
      
      // Re-lanzar el error (ya fue procesado en el bloque anterior)
      throw apiError;
    }

    // Generar formato SRT
    const srt = generateSRT(transcription.segments || []);

    // Identificar speakers (si est√° disponible)
    const speakers = identifySpeakers(transcription.segments || []);

    // Limpiar archivo comprimido temporal despu√©s de la transcripci√≥n exitosa
    // if (compressedAudioPath && existsSync(compressedAudioPath)) {
    //   try {
    //     unlinkSync(compressedAudioPath);
    //     console.log('   üóëÔ∏è  Archivo comprimido temporal eliminado');
    //   } catch (e) {
    //     // Ignorar errores de limpieza
    //   }
    // }

    return {
      transcription: transcription.text,
      srt,
      segments: transcription.segments || [],
      speakers,
    };
  } catch (error) {
    // Limpiar archivo comprimido si hay error
    // if (compressedAudioPath && existsSync(compressedAudioPath)) {
    //   try {
    //     unlinkSync(compressedAudioPath);
    //   } catch (e) {
    //     // Ignorar errores de limpieza
    //   }
    // }
    // Si el error ya tiene un mensaje descriptivo, usarlo; si no, agregar contexto
    if (error.message.includes('Error en transcripci√≥n') || error.message.includes('Error en la API')) {
      throw error;
    }
    throw new Error(`Error en transcripci√≥n: ${error.message}`);
  }
}

/**
 * Genera formato SRT a partir de segmentos
 * @param {Array} segments - Segmentos de la transcripci√≥n
 * @returns {string} - Contenido SRT
 */
function generateSRT(segments) {
  let srt = '';
  
  segments.forEach((segment, index) => {
    const startTime = formatSRTTime(segment.start);
    const endTime = formatSRTTime(segment.end);
    
    srt += `${index + 1}\n`;
    srt += `${startTime} --> ${endTime}\n`;
    srt += `${segment.text.trim()}\n\n`;
  });
  
  return srt;
}

/**
 * Formatea tiempo en formato SRT (HH:MM:SS,mmm)
 * @param {number} seconds - Tiempo en segundos
 * @returns {string} - Tiempo formateado
 */
function formatSRTTime(seconds) {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);
  const milliseconds = Math.floor((seconds % 1) * 1000);
  
  return `${String(hours).padStart(2, '0')}:${String(minutes).padStart(2, '0')}:${String(secs).padStart(2, '0')},${String(milliseconds).padStart(3, '0')}`;
}

/**
 * Identifica speakers en la transcripci√≥n
 * Nota: Whisper no identifica speakers directamente, pero podemos inferir
 * bas√°ndonos en patrones de di√°logo
 * @param {Array} segments - Segmentos de la transcripci√≥n
 * @returns {Array<string>} - Lista de speakers identificados
 */
function identifySpeakers(segments) {
  // Whisper no tiene identificaci√≥n de speakers nativa
  // Por ahora retornamos un array gen√©rico
  // En el futuro se podr√≠a usar diarizaci√≥n de audio
  const speakers = new Set();
  
  // Intentar identificar por patrones comunes
  segments.forEach(segment => {
    const text = segment.text.toLowerCase();
    
    // Patrones que indican conductor/locutor
    if (text.includes('bienvenido') || text.includes('hola') || 
        text.includes('cu√©ntame') || text.includes('dime')) {
      speakers.add('Conductor');
    }
    
    // Si no hay patrones claros, asumir dos speakers
    if (speakers.size === 0) {
      speakers.add('Speaker 1');
      speakers.add('Speaker 2');
    }
  });
  
  return Array.from(speakers).length > 0 
    ? Array.from(speakers) 
    : ['Conductor', 'Llamante'];
}
